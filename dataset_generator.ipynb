{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ====== ⚙️ Settings ⚙️ ===============================\n",
    "days = 100                                  # 학습할 데이터 일수\n",
    "gap_min = 1                                 # 데이터 간격 (분)\n",
    "delta_min = 30                              # 몇분 뒤를 예측할 것인지\n",
    "start_idx = 576000                          # 시작 타임 인덱스 (576000은 40일 후의 인덱스)\n",
    "end_idx = start_idx + days * 24 * 60 * 10   # 실제 마지막 타임 인덱스\n",
    "\n",
    "var_name = 'PWUV'\n",
    "var_list = ['PW', 'USFC', 'VSFC', 'PSFC']  # 사용할 변수 목록\n",
    "\n",
    "base_dir = \"/scratch/x3108a06/input_data/2D/\"\n",
    "input_dir = f'{base_dir}{var_name}_{gap_min}m'\n",
    "pad_dir = f\"{base_dir}{var_name}_d{delta_min}m_{gap_min}m\"\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Data: 100%|██████████| 10081/10081 [00:56<00:00, 178.18it/s]\n",
      "Preprocessing Data: 100%|██████████| 144001/144001 [1:35:46<00:00, 25.06it/s]  \n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "#      .nc to .pt\n",
    "# =======================\n",
    "\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# if not os.path.exists(os.path.join(input_dir, f\"mean_std_{days}d_{gap_min}m.npy\")):\n",
    "mean_array = np.zeros((len(var_list),))\n",
    "mean2_array = np.zeros((len(var_list),))\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(start_idx, start_idx + (days * 24 * 60 * 10) * 7 //10 + 1, gap_min * 100), desc=\"Preprocessing Data\"):\n",
    "    with xr.open_dataset(\n",
    "        f\"/scratch/x3108a06/nc_data/OUT_2D_nc/rcemip_small_awing_96x96x74_1km_6s_300K_48_{i:010d}.2Dcom_1.nc\",\n",
    "        engine=\"netcdf4\"\n",
    "    ) as ds:\n",
    "\n",
    "        ds_sliced = ds[var_list].isel(time=0, drop=True)\n",
    "\n",
    "        data_tensor = torch.stack([\n",
    "            torch.tensor(ds_sliced[var].values, dtype=torch.float32)\n",
    "            for var in var_list\n",
    "        ])  # (C=2, H, W)\n",
    "\n",
    "        # torch.save(data_tensor, os.path.join(input_dir, f\"{i:010d}.pt\"))\n",
    "\n",
    "        # torch.Tensor → numpy 전환 후 평균 계산\n",
    "        data_np = data_tensor.numpy()\n",
    "        z_mean = data_np.mean(axis=(1, 2))      # (C,)\n",
    "        z2_mean = (data_np**2).mean(axis=(1, 2))\n",
    "\n",
    "        mean_array += z_mean\n",
    "        mean2_array += z2_mean\n",
    "        count += 1\n",
    "\n",
    "mean = mean_array / count\n",
    "mean2 = mean2_array / count\n",
    "std = np.sqrt(mean2 - mean**2)\n",
    "\n",
    "np.save(os.path.join(input_dir, f\"mean_std_{days}d_{gap_min}m.npy\"), np.array([mean, std]))\n",
    "\n",
    "\n",
    "# =======================\n",
    "#        padding\n",
    "# =======================\n",
    "\n",
    "\n",
    "def cyclic_pad_2d(x: torch.Tensor, pad: int) -> torch.Tensor:\n",
    "    x = torch.cat([x[..., -pad:, :], x, x[..., :pad, :]], dim=-2)\n",
    "    x = torch.cat([x[..., :, -pad:], x, x[..., :, :pad]], dim=-1)\n",
    "    return x\n",
    "\n",
    "for i in tqdm(range(start_idx, start_idx + days * 24 * 60 * 10 + 1, gap_min * 10), desc=\"Preprocessing Data\"):\n",
    "    with xr.open_dataset(\n",
    "        f\"/scratch/x3108a06/nc_data/OUT_2D_nc/rcemip_small_awing_96x96x74_1km_6s_300K_48_{i:010d}.2Dcom_1.nc\",\n",
    "        engine=\"netcdf4\"\n",
    "    ) as ds:\n",
    "\n",
    "        ds_sliced = ds[var_list].isel(time=0, drop=True)\n",
    "\n",
    "        data_tensor = torch.stack([\n",
    "            cyclic_pad_2d(\n",
    "                (torch.tensor(ds_sliced[var].values, dtype=torch.float32) - mean[j]) / std[j],\n",
    "                16\n",
    "            )\n",
    "            for j, var in enumerate(var_list)\n",
    "        ])  # (C, H, W)\n",
    "\n",
    "        torch.save(data_tensor, os.path.join(input_dir, f\"{i:010d}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144001it [06:26, 372.26it/s] \n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "#      (x, y) stack\n",
    "# =======================\n",
    "\n",
    "# x, y를 첫번째 차원으로 쌓아서 (2, C, H, W) 모양의 텐서를 만드는 코드\n",
    "\n",
    "os.makedirs(pad_dir, exist_ok=True)\n",
    "\n",
    "# 파일 리스트 정렬\n",
    "filelist = sorted([f for f in os.listdir(input_dir) if f.endswith('.pt')])\n",
    "N = len(filelist)\n",
    "\n",
    "# 몇번째 뒤와 x, y쌍으로 묶을 것인지\n",
    "shift = delta_min // gap_min\n",
    "\n",
    "for idx, fname in tqdm(enumerate(filelist)):  # type: int, str\n",
    "    # 최종 결과 파일의 경로를 먼저 확인합니다.\n",
    "    output_fpath = os.path.join(pad_dir, fname)\n",
    "\n",
    "    # 만약 결과 파일이 이미 존재한다면, 이번 순서는 건너뜁니다.\n",
    "    if os.path.exists(output_fpath):\n",
    "        continue  # 다음 파일로 바로 넘어감\n",
    "\n",
    "    fpath = os.path.join(input_dir, fname)\n",
    "    data = torch.load(fpath, map_location='cpu')\n",
    "    if not isinstance(data, torch.Tensor):\n",
    "        print(f\"{fname}: Not a tensor, skipped.\")\n",
    "        continue\n",
    "\n",
    "    # 현재 파일\n",
    "    # padded_0 = cyclic_pad_2d(data, 16)\n",
    "\n",
    "    # shift만큼 뒤 파일(없으면 마지막 파일 사용)\n",
    "    shifted_idx = min(idx + shift, N - 1)\n",
    "    shifted_fname = filelist[shifted_idx]\n",
    "    shifted_fpath = os.path.join(input_dir, shifted_fname)\n",
    "    shifted_data = torch.load(shifted_fpath, map_location='cpu')\n",
    "    \n",
    "    # padded_1 = cyclic_pad_2d(shifted_data, 16)\n",
    "\n",
    "    # (2, 128, 128) 저장\n",
    "    out = torch.stack([data, shifted_data], dim=0)\n",
    "    torch.save(out, os.path.join(pad_dir, fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PWUV_d30m_1m] Total: 144001 -> train: 100800, valid: 21600, test: 21601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 100800/100800 [00:02<00:00, 46451.95it/s]\n",
      "valid: 100%|██████████| 21600/21600 [00:00<00:00, 46849.77it/s]\n",
      "test: 100%|██████████| 21601/21601 [00:00<00:00, 53621.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "#    train test split\n",
    "# =======================\n",
    "\n",
    "import shutil\n",
    "from math import floor\n",
    "\n",
    "\n",
    "# 앞에서부터 70%를 train으로, 15%를 valid로, 15%를 test 셋으로 분리하여 저장하는 코드\n",
    "\n",
    "def split_and_copy(src_dir, dst_base, prefix='', total_limit=None):\n",
    "    os.makedirs(dst_base, exist_ok=True)\n",
    "    files = sorted([f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))])\n",
    "    if total_limit:\n",
    "        files = files[:total_limit]\n",
    "    n = len(files)\n",
    "    n_train = floor(n * 0.7)\n",
    "    n_valid = floor(n * 0.15)\n",
    "    n_test = n - n_train - n_valid\n",
    "\n",
    "    splits = [\n",
    "        ('train', n_train),\n",
    "        ('valid', n_valid),\n",
    "        ('test', n_test),\n",
    "    ]\n",
    "\n",
    "    print(f\"[{prefix}] Total: {n} -> train: {n_train}, valid: {n_valid}, test: {n_test}\")\n",
    "\n",
    "    idx = 0\n",
    "    for split, count in splits:\n",
    "        dst_dir = os.path.join(dst_base, prefix, split)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        for i in tqdm(range(count), desc=split):\n",
    "            src_path = os.path.join(src_dir, files[idx])\n",
    "            dst_path = os.path.join(dst_dir, files[idx])\n",
    "            idx += 1\n",
    "            if os.path.exists(dst_path):\n",
    "                continue  # 다음 파일로 바로 넘어감\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "\n",
    "# ============== settings ====================\n",
    "split_and_copy(\n",
    "    src_dir=pad_dir,\n",
    "    dst_base=base_dir,\n",
    "    prefix=f'{var_name}_d{delta_min}m_{gap_min}m',\n",
    "    total_limit=None\n",
    ")\n",
    "# ============================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
