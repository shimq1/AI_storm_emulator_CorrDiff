{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Data: 100%|██████████| 10081/10081 [06:47<00:00, 24.77it/s]\n",
      "Preprocessing Data:   0%|          | 0/144001 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cyclic_pad_2d() missing 1 required positional argument: 'pad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/scratch/x3108a06/corrdiff/dataset_generator.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mwith\u001b[39;00m xr\u001b[39m.\u001b[39mopen_dataset(\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/scratch/x3108a06/nc_data/OUT_2D_nc/rcemip_small_awing_96x96x74_1km_6s_300K_48_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m010d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.2Dcom_1.nc\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnetcdf4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m ) \u001b[39mas\u001b[39;00m ds:\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m     ds_sliced \u001b[39m=\u001b[39m ds[var_list]\u001b[39m.\u001b[39misel(time\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     data_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m         (cyclic_pad_2d(\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m             torch\u001b[39m.\u001b[39mtensor(ds_sliced[var]\u001b[39m.\u001b[39mvalues, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32) \u001b[39m-\u001b[39m mean[j]) \u001b[39m/\u001b[39m std[j],\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m             \u001b[39m16\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m         \u001b[39mfor\u001b[39;00m j, var \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(var_list)]\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m     )  \u001b[39m# (C, H, W)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m     torch\u001b[39m.\u001b[39msave(data_tensor, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(input_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m010d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;32m/scratch/x3108a06/corrdiff/dataset_generator.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mwith\u001b[39;00m xr\u001b[39m.\u001b[39mopen_dataset(\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/scratch/x3108a06/nc_data/OUT_2D_nc/rcemip_small_awing_96x96x74_1km_6s_300K_48_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m010d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.2Dcom_1.nc\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnetcdf4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m ) \u001b[39mas\u001b[39;00m ds:\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m     ds_sliced \u001b[39m=\u001b[39m ds[var_list]\u001b[39m.\u001b[39misel(time\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     data_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\n\u001b[0;32m---> <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m         (cyclic_pad_2d(\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m             torch\u001b[39m.\u001b[39;49mtensor(ds_sliced[var]\u001b[39m.\u001b[39;49mvalues, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32) \u001b[39m-\u001b[39;49m mean[j]) \u001b[39m/\u001b[39m std[j],\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m             \u001b[39m16\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m         \u001b[39mfor\u001b[39;00m j, var \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(var_list)]\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m     )  \u001b[39m# (C, H, W)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://haw5bj4c.my.ksc.re.kr/scratch/x3108a06/corrdiff/dataset_generator.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m     torch\u001b[39m.\u001b[39msave(data_tensor, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(input_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m010d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: cyclic_pad_2d() missing 1 required positional argument: 'pad'"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "#      .nc to .pt\n",
    "# =======================\n",
    "\n",
    "\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ====== ⚙️ Settings ⚙️ ===============================\n",
    "days = 100                                  # 학습할 데이터 일수\n",
    "gap_min = 1                                 # 데이터 간격 (분)        \n",
    "start_idx = 576000                          # 시작 타임 인덱스 (576000은 40일 후의 인덱스)\n",
    "end_idx = start_idx + days * 24 * 60 * 10   # 실제 마지막 타임 인덱스\n",
    "\n",
    "var_name = 'PWUV'\n",
    "var_list = ['PW', 'USFC', 'VSFC', 'PSFC']  # 사용할 변수 목록\n",
    "\n",
    "base_dir = \"/scratch/x3108a06/input_data/2D/\"\n",
    "input_dir = f'{base_dir}{var_name}_{gap_min}m'\n",
    "pad_dir = f\"{base_dir}{var_name}_pad_{gap_min}m\"\n",
    "# ========================================================\n",
    "\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# if not os.path.exists(os.path.join(input_dir, f\"mean_std_{days}d_{gap_min}m.npy\")):\n",
    "mean_array = np.zeros((len(var_list),))\n",
    "mean2_array = np.zeros((len(var_list),))\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(start_idx, start_idx + (days * 24 * 60 * 10) * 7 //10 + 1, gap_min * 100), desc=\"Preprocessing Data\"):\n",
    "    with xr.open_dataset(\n",
    "        f\"/scratch/x3108a06/nc_data/OUT_2D_nc/rcemip_small_awing_96x96x74_1km_6s_300K_48_{i:010d}.2Dcom_1.nc\",\n",
    "        engine=\"netcdf4\"\n",
    "    ) as ds:\n",
    "\n",
    "        ds_sliced = ds[var_list].isel(time=0, drop=True)\n",
    "\n",
    "        data_tensor = torch.stack([\n",
    "            torch.tensor(ds_sliced[var].values, dtype=torch.float32)\n",
    "            for var in var_list\n",
    "        ])  # (C=2, H, W)\n",
    "\n",
    "        # torch.save(data_tensor, os.path.join(input_dir, f\"{i:010d}.pt\"))\n",
    "\n",
    "        # torch.Tensor → numpy 전환 후 평균 계산\n",
    "        data_np = data_tensor.numpy()\n",
    "        z_mean = data_np.mean(axis=(1, 2))      # (C,)\n",
    "        z2_mean = (data_np**2).mean(axis=(1, 2))\n",
    "\n",
    "        mean_array += z_mean\n",
    "        mean2_array += z2_mean\n",
    "        count += 1\n",
    "\n",
    "mean = mean_array / count\n",
    "mean2 = mean2_array / count\n",
    "std = np.sqrt(mean2 - mean**2)\n",
    "\n",
    "np.save(os.path.join(input_dir, f\"mean_std_{days}d_{gap_min}m.npy\"), np.array([mean, std]))\n",
    "\n",
    "\n",
    "def cyclic_pad_2d(x: torch.Tensor, pad: int) -> torch.Tensor:\n",
    "    x = torch.cat([x[..., -pad:, :], x, x[..., :pad, :]], dim=-2)\n",
    "    x = torch.cat([x[..., :, -pad:], x, x[..., :, :pad]], dim=-1)\n",
    "    return x\n",
    "\n",
    "for i in tqdm(range(start_idx, start_idx + days * 24 * 60 * 10 + 1, gap_min * 10), desc=\"Preprocessing Data\"):\n",
    "    with xr.open_dataset(\n",
    "        f\"/scratch/x3108a06/nc_data/OUT_2D_nc/rcemip_small_awing_96x96x74_1km_6s_300K_48_{i:010d}.2Dcom_1.nc\",\n",
    "        engine=\"netcdf4\"\n",
    "    ) as ds:\n",
    "\n",
    "        ds_sliced = ds[var_list].isel(time=0, drop=True)\n",
    "\n",
    "        data_tensor = torch.stack([\n",
    "            cyclic_pad_2d(\n",
    "                (torch.tensor(ds_sliced[var].values, dtype=torch.float32) - mean[j]) / std[j],\n",
    "                16\n",
    "            )\n",
    "            for j, var in enumerate(var_list)\n",
    "        ])  # (C, H, W)\n",
    "\n",
    "        torch.save(data_tensor, os.path.join(input_dir, f\"{i:010d}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "#        padding\n",
    "# =======================\n",
    "\n",
    "# cyclic padding을 적용함과 동시에\n",
    "# x, y를 첫번째 차원으로 쌓아서 (2, C, H, W) 모양의 텐서를 만드는 코드\n",
    "\n",
    "os.makedirs(pad_dir, exist_ok=True)\n",
    "\n",
    "# 파일 리스트 정렬\n",
    "filelist = sorted([f for f in os.listdir(input_dir) if f.endswith('.pt')])\n",
    "N = len(filelist)\n",
    "\n",
    "# 몇번째 뒤와 x, y쌍으로 묶을 것인지\n",
    "shift = 30 / gap_min\n",
    "\n",
    "for idx, fname in tqdm(enumerate(filelist)):  # type: int, str\n",
    "    fpath = os.path.join(input_dir, fname)\n",
    "    data = torch.load(fpath, map_location='cpu')\n",
    "    if not isinstance(data, torch.Tensor):\n",
    "        print(f\"{fname}: Not a tensor, skipped.\")\n",
    "        continue\n",
    "\n",
    "    # 현재 파일\n",
    "    # padded_0 = cyclic_pad_2d(data, 16)\n",
    "\n",
    "    # shift만큼 뒤 파일(없으면 마지막 파일 사용)\n",
    "    shifted_idx = min(idx + shift, N - 1)\n",
    "    shifted_fname = filelist[shifted_idx]\n",
    "    shifted_fpath = os.path.join(input_dir, shifted_fname)\n",
    "    shifted_data = torch.load(shifted_fpath, map_location='cpu')\n",
    "    \n",
    "    # padded_1 = cyclic_pad_2d(shifted_data, 16)\n",
    "\n",
    "    # (2, 128, 128) 저장\n",
    "    out = torch.stack([data, shifted_data], dim=0)\n",
    "    torch.save(out, os.path.join(pad_dir, fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "#    train test split\n",
    "# =======================\n",
    "\n",
    "import shutil\n",
    "from math import floor\n",
    "\n",
    "\n",
    "# 앞에서부터 70%를 train으로, 15%를 valid로, 15%를 test 셋으로 분리하여 저장하는 코드\n",
    "\n",
    "def split_and_copy(src_dir, dst_base, prefix='', total_limit=None):\n",
    "    os.makedirs(dst_base, exist_ok=True)\n",
    "    files = sorted([f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))])\n",
    "    if total_limit:\n",
    "        files = files[:total_limit]\n",
    "    n = len(files)\n",
    "    n_train = floor(n * 0.7)\n",
    "    n_valid = floor(n * 0.15)\n",
    "    n_test = n - n_train - n_valid\n",
    "\n",
    "    splits = [\n",
    "        ('train', n_train),\n",
    "        ('valid', n_valid),\n",
    "        ('test', n_test),\n",
    "    ]\n",
    "\n",
    "    print(f\"[{prefix}] Total: {n} -> train: {n_train}, valid: {n_valid}, test: {n_test}\")\n",
    "\n",
    "    idx = 0\n",
    "    for split, count in splits:\n",
    "        dst_dir = os.path.join(dst_base, prefix, split)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        for i in tqdm(range(count), desc=split):\n",
    "            src_path = os.path.join(src_dir, files[idx])\n",
    "            dst_path = os.path.join(dst_dir, files[idx])\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "# ============== settings ====================\n",
    "split_and_copy(\n",
    "    src_dir=pad_dir,\n",
    "    dst_base=base_dir,\n",
    "    prefix=f'{var_name}_pad_{gap_min}m',\n",
    "    total_limit=None\n",
    ")\n",
    "# ============================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
