# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import contextlib
from concurrent.futures import ThreadPoolExecutor
from functools import partial

import hydra
from omegaconf import OmegaConf, DictConfig
from hydra.utils import to_absolute_path
import torch
import torch._dynamo
from torch.distributed import gather
import numpy as np
import nvtx
import netCDF4 as nc
import pandas as pd

import sys

sys.path.insert(0, "/data03/SAM/physicsnemo")
from physicsnemo.distributed import DistributedManager
from physicsnemo.launch.logging import PythonLogger, RankZeroLoggingWrapper
from physicsnemo.utils.patching import GridPatching2D
from physicsnemo import Module
from physicsnemo.utils.diffusion import deterministic_sampler, stochastic_sampler
from utils import (
    NetCDFWriter,
    get_time_from_range,
    regression_step,
    diffusion_step,
)

from helpers.generate_helpers import (
    get_dataset_and_sampler,
    save_images,
)

from helpers.train_helpers import set_patch_shape
from datasets.dataset import register_dataset

forecast_time_min = 6 #! <--- ì˜ˆì¸¡ ì‹œê°„ (ë¶„) ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ì„ ë°›ì„ ìˆ˜ ìˆê²Œ ë°”ê¿”ì•¼ í•  ë“¯

@hydra.main(version_base="1.2", config_path="conf", config_name="config_generate")
def main(cfg: DictConfig) -> None:
    """
    ì„¤ì • íŒŒì¼(cfg)ì— ë”°ë¼ ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , ë°ì´í„°ì…‹ìœ¼ë¡œë¶€í„° ì…ë ¥ì„ ë°›ì•„
    ì´ë¯¸ì§€(ê²°ê³¼ì¥)ë¥¼ ìƒì„±í•˜ì—¬ NetCDF íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸.
    Autoregressive ëª¨ë“œë¥¼ ì§€ì›.
    """
    # --- 2. ì´ˆê¸° ì„¤ì • ë° ë¶„ì‚° ì²˜ë¦¬ ì´ˆê¸°í™” ---
    is_autoregressive = cfg.generation.get("autoregressive", {}).get("enabled", False)
    DistributedManager.initialize()
    dist = DistributedManager()
    device = dist.device
    logger = PythonLogger("generate")
    logger0 = RankZeroLoggingWrapper(logger, dist)
    logger.file_logging("generate.log")

    # ì•™ìƒë¸” ë° ë°°ì¹˜ í¬ê¸° ì„¤ì •
    seeds = list(np.arange(cfg.generation.num_ensembles))
    num_batches = (
        (len(seeds) - 1) // (cfg.generation.seed_batch_size * dist.world_size) + 1
    ) * dist.world_size
    all_batches = torch.as_tensor(seeds).tensor_split(num_batches)
    rank_batches = all_batches[dist.rank :: dist.world_size]

    if dist.world_size > 1:
        torch.distributed.barrier()

    # --- 3. ë°ì´í„° ë¡œë”©ì„ ìœ„í•œ ì‹œê°„ ì •ë³´ íŒŒì‹± ---
    if getattr(cfg.generation, "times_range", None) and getattr(cfg.generation, "times", None):
        raise ValueError("times_rangeì™€ times ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
    
    # Use times even in case of autoregressive generation
    times = get_time_from_range(cfg.generation.times_range) if cfg.generation.times_range else cfg.generation.times

    logger0.info(f"Using times: {times}")
    # --- 4. ë°ì´í„°ì…‹ ë° ëª¨ë¸ ê´€ë ¨ ì„¤ì • ---
    dataset_cfg = OmegaConf.to_container(cfg.dataset)
    register_dataset(cfg.dataset.type)
    logger0.info(f"Using dataset: {cfg.dataset.type}")
    has_lead_time = cfg.generation.get("has_lead_time", False)
    dataset, sampler = get_dataset_and_sampler(
        dataset_cfg=dataset_cfg, times=times, has_lead_time=has_lead_time
    )
    img_shape = dataset.image_shape()
    img_out_channels = len(dataset.output_channels())
    # Parse the patch shape
    if cfg.generation.patching:
        patch_shape_x = cfg.generation.patch_shape_x
        patch_shape_y = cfg.generation.patch_shape_y
    else:
        patch_shape_x, patch_shape_y = None, None
    patch_shape = (patch_shape_y, patch_shape_x)
    use_patching, img_shape, patch_shape = set_patch_shape(img_shape, patch_shape)
    if use_patching:
        patching = GridPatching2D(
            img_shape=img_shape,
            patch_shape=patch_shape,
            boundary_pix=cfg.generation.boundary_pix,
            overlap_pix=cfg.generation.overlap_pix,
        )
        logger0.info("Patch-based training enabled")
    else:
        patching = None
        logger0.info("Patch-based training disabled")

    # Parse the inference mode
    if cfg.generation.inference_mode == "regression":
        load_net_reg, load_net_res = True, False
    elif cfg.generation.inference_mode == "diffusion":
        load_net_reg, load_net_res = False, True
    elif cfg.generation.inference_mode == "all":
        load_net_reg, load_net_res = True, True
    else:
        raise ValueError(f"Invalid inference mode {cfg.generation.inference_mode}")

    # Load diffusion network, move to device, change precision
    if load_net_res:
        res_ckpt_filename = cfg.generation.io.res_ckpt_filename
        logger0.info(f'Loading residual network from "{res_ckpt_filename}"...')
        net_res = Module.from_checkpoint(to_absolute_path(res_ckpt_filename))
        net_res = net_res.eval().to(device).to(memory_format=torch.channels_last)
        if cfg.generation.perf.force_fp16:
            net_res.use_fp16 = True
        # Disable AMP for inference (even if model is trained with AMP)
        if hasattr(net_res, "amp_mode"):
            net_res.amp_mode = False
    else:
        net_res = None

    # load regression network, move to device, change precision
    if load_net_reg:
        reg_ckpt_filename = cfg.generation.io.reg_ckpt_filename
        logger0.info(f'Loading network from "{reg_ckpt_filename}"...')
        net_reg = Module.from_checkpoint(to_absolute_path(reg_ckpt_filename))
        net_reg = net_reg.eval().to(device).to(memory_format=torch.channels_last)
        if cfg.generation.perf.force_fp16:
            net_reg.use_fp16 = True
        # Disable AMP for inference (even if model is trained with AMP)
        if hasattr(net_reg, "amp_mode"):
            net_reg.amp_mode = False
    else:
        net_reg = None

    # Reset since we are using a different mode.
    if cfg.generation.perf.use_torch_compile:
        torch._dynamo.reset()
        if net_res:
            net_res = torch.compile(net_res, mode="reduce-overhead")

    # Partially instantiate the sampler based on the configs
    if cfg.sampler.type == "deterministic":
        if cfg.generation.hr_mean_conditioning:
            raise NotImplementedError(
                "High-res mean conditioning is not yet implemented for the deterministic sampler"
            )
        sampler_fn = partial(
            deterministic_sampler,
            num_steps=cfg.sampler.num_steps,
            solver=cfg.sampler.solver,
        )
    elif cfg.sampler.type == "stochastic":
        sampler_fn = partial(stochastic_sampler, patching=patching)
    else:
        raise ValueError(f"Unknown sampling method {cfg.sampling.type}")

    # --- AUTOREGRESSIVE: generate_fnì„ ìˆ˜ì •í•˜ì—¬ image_lrì„ ì¸ìë¡œ ë°›ë„ë¡ í•¨ ---
    def generate_fn(current_image_lr, lead_time_label):
        """í•œ ìŠ¤í…ì˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³ , ìµœì¢… ê²°ê³¼ì™€ íšŒê·€ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
        with nvtx.annotate("generate_fn", color="green"):
            img_lr = current_image_lr.to(device=device).to(torch.float32).to(memory_format=torch.channels_last)
            
            image_reg, image_res = None, None # ê²°ê³¼ ë³€ìˆ˜ ì´ˆê¸°í™”

            # íšŒê·€ ëª¨ë¸ ì‹¤í–‰
            if net_reg:
                with nvtx.annotate("regression_model", color="yellow"):
                    image_reg = regression_step(
                        net=net_reg, img_lr=img_lr,
                        latents_shape=(cfg.generation.seed_batch_size, img_out_channels, img_shape[0], img_shape[1]),
                        lead_time_label=lead_time_label,
                    )
            # í™•ì‚° ëª¨ë¸ ì‹¤í–‰
            if net_res:
                with nvtx.annotate("diffusion model", color="purple"):
                    mean_hr = image_reg[0:1] if cfg.generation.hr_mean_conditioning else None
                    image_res = diffusion_step(
                        net=net_res, sampler_fn=sampler_fn, img_shape=img_shape, img_out_channels=img_out_channels,
                        rank_batches=rank_batches, img_lr=img_lr.expand(cfg.generation.seed_batch_size, -1, -1, -1).to(memory_format=torch.channels_last),
                        rank=dist.rank, device=device, mean_hr=mean_hr, lead_time_label=lead_time_label,
                    )

            # ìµœì¢… ì¶œë ¥ ê²°ì •
            if cfg.generation.inference_mode == "regression":
                image_out = image_reg
            elif cfg.generation.inference_mode == "diffusion":
                image_out = image_res
            else: # "all" ëª¨ë“œ
                image_out = image_reg + image_res

            # ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: image_regë„ í•¨ê»˜ ë°˜í™˜ (all ëª¨ë“œì¼ ë•Œë§Œ)
            image_reg_to_return = image_reg if cfg.generation.inference_mode == "all" else None
            
            # ë‹¤ì¤‘ GPU ì²˜ë¦¬ ë¡œì§ (ë³µì¡ì„±ìœ¼ë¡œ ì¸í•´ ì—¬ê¸°ì„œëŠ” ìƒëµ, ë‹¨ì¼ GPU ê°€ì •)
            # TODO: ë‹¤ì¤‘ GPU í™˜ê²½ì—ì„œ íŠœí”Œì„ gather í•˜ë ¤ë©´ ë³„ë„ ì²˜ë¦¬ í•„ìš”
            return image_out, image_reg_to_return

    # --- ë©”ì¸ ë¡œì§ ë¶„ê¸° (Autoregressive ëª¨ë“œ vs ì¼ë°˜ ëª¨ë“œ) ---
    if is_autoregressive:
        # --------------------------------------------------
        # --- AUTOREGRESSIVE ì˜ˆì¸¡ ë¡œì§ ---
        # --------------------------------------------------
        num_auto_steps = cfg.generation.autoregressive.num_auto_steps
        logger0.info(f"Starting autoregressive forecast for {num_auto_steps} steps.")

        output_path = getattr(cfg.generation.io, "output_filename", "corrdiff_output.nc")
        logger0.info(f"Generating images, saving results to {output_path}...")

        # DataLoader according to designated times array
        data_loader = torch.utils.data.DataLoader(dataset=dataset, sampler=sampler, batch_size=1, pin_memory=True)
        time_index = -1

        times_from_dataset = dataset.time()

        predictions_total_list = []
        inputs_total_list = []
        regressions_total_list = []
        truths_total_list = []
        for index, (image_tar, initial_lr, *lead_time_label) in enumerate(iter(data_loader)):
            if lead_time_label:
                lead_time_label = lead_time_label[0].to(dist.device).contiguous()
            else:
                lead_time_label = None

            # --- 7a. ì •ë‹µ(Truth) ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ (ìˆ˜ì •ëœ í•µì‹¬ ë¡œì§) ---
            # ì˜ˆì¸¡í•  ëª¨ë“  ì‹œê°„ ë‹¨ê³„ì— ëŒ€í•œ ì‹¤ì œ ì •ë‹µ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ë¶ˆëŸ¬ì˜´
            logger0.info("Loading ground truth data for all forecast steps...")
            start_time = pd.to_datetime(times[index])
            time_delta = pd.Timedelta(minutes=forecast_time_min) # 30ë¶„ ê°„ê²©
            # ì˜ˆì¸¡ì— í•„ìš”í•œ ëª¨ë“  ì‹œê°„ ëª©ë¡ ìƒì„±
            truth_times = [start_time + i * time_delta for i in range(num_auto_steps)]
            truth_times_str = [t.strftime("%Y-%m-%dT%H:%M:%S") for t in truth_times]

            # ì •ë‹µ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ ë³„ë„ì˜ ë°ì´í„°ì…‹ê³¼ ë°ì´í„°ë¡œë” ìƒì„±
            truth_dataset, truth_sampler = get_dataset_and_sampler(
                dataset_cfg=dataset_cfg, times=truth_times_str, has_lead_time=has_lead_time
            )
            truth_data_loader = torch.utils.data.DataLoader(dataset=truth_dataset, sampler=truth_sampler, batch_size=1, pin_memory=True)
            logger0.info(f"Loaded ground truth dataset with {len(truth_dataset)} samples for times: {truth_times_str}")
            # ëª¨ë“  ì •ë‹µ ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ë©° ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
            truths_list = []
            for _, image_tar, *_ in iter(truth_data_loader):
                truths_list.append(image_tar.cpu())
            # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ ê²°í•©
            truths_single_time = torch.cat(truths_list, dim=0)
            logger0.info(f"Loaded {len(truths_single_time)} ground truth steps.")


            # --- 7b. ì—°ì‡„ ì˜ˆì¸¡ ìˆ˜í–‰ ---
            current_lr = initial_lr
            
            predictions_list = []
            regressions_list = []

            # ì—°ì‡„ ì˜ˆì¸¡ ë£¨í”„
            for step in range(num_auto_steps):
                logger0.info(f"  - Autoregressive step {step + 1}/{num_auto_steps}...")
                # ğŸ’¡ ìˆ˜ì •: ì´ì œ 2ê°œì˜ ê°’ì„ ë°˜í™˜ë°›ìŒ
                predicted_out, predicted_reg = generate_fn(current_lr, lead_time_label)

                if dist.rank == 0:
                    predictions_list.append(predicted_out.cpu())
                    if predicted_reg is not None:
                        regressions_list.append(predicted_reg.cpu())

                        
                # Which output to use as input for the next step (Default: ENS_mean = Diffusion ens mean, regression = U-Net, diffusion = Diffusion 1st member)
                out2input = getattr(cfg.generation.autoregressive, "out2input", "ENS_mean")
                if out2input == "regression":
                    current_lr = predicted_reg
                elif out2input == "diffusion":
                    current_lr = predicted_out[0].unsqueeze(0)
                elif out2input == "ENS_mean":
                    current_lr = predicted_out.mean(dim=0, keepdim=True)

            predictions_total_list.append(torch.stack(predictions_list))
            inputs_total_list.append(initial_lr.squeeze(0).cpu())
            if predicted_reg is not None:
                regressions_total_list.append(torch.stack(regressions_list))
            truths_total_list.append(truths_single_time)

        # --- 7c. ê²°ê³¼ ì €ì¥ ---
        # --------------------------------------------------
        # Data Dimensions
        # Input: (Time, X, Y, Channel)
        # Truth: (Time, Step, X, Y, Channel)
        # Unet : (Time, Step, X, Y, Channel)
        # Pred : (Ens , Time, Step, X, Y, Channel)
        # --------------------------------------------------
        if dist.rank == 0:
            output_path = getattr(cfg.generation.io, "output_filename", "corrdiff_output.nc")
            logger0.info(f"Autoregressive forecast finished. Saving results to {output_path}...")
            
            all_predictions = torch.stack(predictions_total_list, dim=0)
            all_inputs = torch.stack(inputs_total_list, dim=0)
            all_truths = torch.stack(truths_total_list, dim=0)
            logger0.info(f"Total predictions shape: {all_predictions.shape}, inputs shape: {all_inputs.shape}, truths shape: {all_truths.shape}")

            with nc.Dataset(output_path, "w") as f:
                f.cfg = str(cfg)
                writer = NetCDFWriter(
                    f, lat=dataset.latitude(), lon=dataset.longitude(),
                    input_channels=dataset.input_channels(), output_channels=dataset.output_channels(),
                    has_lead_time=has_lead_time, autoregressive_opt=is_autoregressive  # âœ… _opt ë§ì¶”ê¸°
                )
                
                # Prediction ë°ì´í„° ì €ì¥ (ì´ì „ê³¼ ë™ì¼)
                output_channels_meta = dataset.output_channels()
                prediction_to_save = all_predictions.permute(2, 0, 1, 4, 5, 3).numpy() # (time, step, ens, channel, x, y) -> (ensemble, time, step, x ,y ,channel)
                num_ensembles = prediction_to_save.shape[0]
                num_times = prediction_to_save.shape[1]
                num_auto_steps = prediction_to_save.shape[2]

                print(f"num_auto_steps = {num_auto_steps}")
                for ens_idx in range(num_ensembles):
                    for time_idx in range(num_times):
                        for step_idx in range(num_auto_steps):
                            for chan_idx, chan_meta in enumerate(output_channels_meta):
                                data_slice = prediction_to_save[ens_idx, time_idx, step_idx, :, :, chan_idx]
                                writer.write_prediction(val=data_slice, time_index=time_idx, ensemble_index=ens_idx, step_index=step_idx, channel_name=chan_meta.name)

                # Input ë°ì´í„° ì €ì¥ (ì´ì „ê³¼ ë™ì¼)
                input_channels_meta = dataset.input_channels()
                input_to_save = all_inputs.permute(0, 2, 3, 1).numpy() # (time, channel, x, y) -> (time, x ,y ,channel)
                for time_idx in range(num_times):
                    for chan_idx, chan_meta in enumerate(input_channels_meta):
                        data_slice = input_to_save[time_idx, :, :, chan_idx]
                        writer.write_input(val=data_slice, time_index=time_idx, channel_name=chan_meta.name)

                # Truth ë°ì´í„° ì €ì¥ (ìˆ˜ì •ëœ ë¡œì§)
                truth_to_save = all_truths.permute(0, 1, 3, 4, 2).numpy() # (time, step, channel, x, y)) -> (time, step, x ,y ,channel)
                for time_idx in range(num_times):
                    for step_idx in range(num_auto_steps):
                        for chan_idx, chan_meta in enumerate(output_channels_meta):
                            data_slice = truth_to_save[time_idx, step_idx, :, :, chan_idx]
                            writer.write_truth(val=data_slice, time_index=time_idx, step_index=step_idx, channel_name=chan_meta.name)

                # ğŸ’¡ ì¶”ê°€: Regression ê·¸ë£¹ì— ê²°ê³¼ ì €ì¥
                if cfg.generation.inference_mode == 'all' and regressions_total_list:
                    logger0.info("Saving regression-only output to 'regression' group...")
                    all_regressions = torch.stack(regressions_total_list, dim=0)
                    logger0.info(f"Total regression shape: {all_regressions.shape}")
                    reg_to_save = all_regressions.permute(2, 0, 1, 4, 5, 3).squeeze(0).numpy()
                    
                    # NetCDF4 ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ê·¸ë£¹ê³¼ ë³€ìˆ˜ ìƒì„±
                    reg_group = f.createGroup('regression')
                    reg_group.createDimension('time', num_times)
                    reg_group.createDimension('step', num_auto_steps)
                    reg_group.createDimension('y', img_shape[0])
                    reg_group.createDimension('x', img_shape[1])

                    output_channels_meta = dataset.output_channels()
                    for chan_idx, chan_meta in enumerate(output_channels_meta):
                        var = reg_group.createVariable(chan_meta.name, 'f4', ('time', 'step', 'y', 'x'))
                        var[:] = reg_to_save[:, :, :, :, chan_idx]


    else:
        # --------------------------------------------------
        # --- ê¸°ì¡´ì˜ ë‹¨ì¼ ì˜ˆì¸¡ ë¡œì§ ---
        # --------------------------------------------------
        output_path = getattr(cfg.generation.io, "output_filename", "corrdiff_output.nc")
        logger0.info(f"Generating images, saving results to {output_path}...")
        batch_size = 1
        warmup_steps = min(len(times) - 1, 2)
        if dist.rank == 0:
            f = nc.Dataset(output_path, "w")
            f.cfg = str(cfg)

        data_loader = torch.utils.data.DataLoader(dataset=dataset, sampler=sampler, batch_size=1, pin_memory=True)
        time_index = -1
        if dist.rank == 0:
            writer = NetCDFWriter(f, lat=dataset.latitude(), lon=dataset.longitude(), input_channels=dataset.input_channels(), output_channels=dataset.output_channels(), has_lead_time=has_lead_time)
            writer_executor = ThreadPoolExecutor(max_workers=cfg.generation.perf.num_writer_workers)
            writer_threads = []

        times_from_dataset = dataset.time()
        for index, (image_tar, image_lr, *lead_time_label) in enumerate(iter(data_loader)):
            time_index += 1
            if dist.rank == 0: logger0.info(f"starting index: {time_index}")

            if lead_time_label:
                lead_time_label = lead_time_label[0].to(dist.device).contiguous()
            else:
                lead_time_label = None

            # generate_fnì€ current_image_lr, lead_time_label ì¸ìë¥¼ ë°›ë„ë¡ ìˆ˜ì •ë˜ì—ˆìœ¼ë¯€ë¡œ ë§ì¶°ì„œ í˜¸ì¶œ
            image_out = generate_fn(image_lr, lead_time_label)
            
            if dist.rank == 0:
                batch_size = image_out.shape[0]
                writer_threads.append(
                    writer_executor.submit(
                        save_images, writer, dataset, list(times_from_dataset), 
                        image_out.cpu(), image_tar.cpu(), image_lr.cpu(), 
                        time_index, index, has_lead_time
                    )
                )
        
        if dist.rank == 0:
            for thread in list(writer_threads):
                thread.result()
                writer_threads.remove(thread)
            writer_executor.shutdown()
        
        if dist.rank == 0:
            f.close()
            
    logger0.info("Generation Completed.")

if __name__ == "__main__":
    main()
